# load, split and scale the maps dataset ready for training
from os import listdir
from numpy import asarray
from numpy import vstack
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
from numpy import savez_compressed
from numpy import load
# dataset path
path_original_images = "C:/Users/nadee/Documents/Mountains/valid/"
# path_processed = "testDataUnfiltered/scaled_processed_downsized/"
path_processed_images = "C:/Users/nadee/Documents/Mountains/caravaggio/traced-images/"
filename = "C:/Users/nadee/Documents/Mountains/mountains_Diego.npz"
ignore_list = {
    8,
    9,
    11,
    12,
    13,
    20,
    21,
    25,
    31,
    32,
    33,
    34,
    36,
    38,
    41,
    42,
    51,
    57,
    63,
    66,
    69,
    71,
    74,
    77,
    85,
    89,
    90,
    91,
    94,
    101,
    104,
    110,
    112,
    122,
    137,
    142,
    151,
    153,
    159,
    167,
    168,
    169,
    170,
    171,
    172,
    176,
    180,
    181,
    184,
    185,
    194,
    195,
    196,
    197,
    207,
    218,
    227,
    228,
    229,
    243,
    248,
    257,
    259,
    283,
    290,
    300,
    309,
    316,
    319,
    320,
    321,
    325,
    338,
    342,
    349,
    366,
    372,
    381,
    385,
    387,
    396,
    414,
    416,
    423,
    424,
    425,
    429,
    432,
    433,
    438,
    441,
    448,
    449,
    456,
    471,
    481,
    482,
    493,
    500,
    503,
    514,
    520,
    522,
    536,
    539,
    546,
    547,
    554,
    555,
    557,
    558,
    561,
    568,
    569,
    570,
    576,
    581,
    586,
    589,
    595,
    603,
    604,
    606,
    607,
    610,
    611,
    616,
    620,
    638,
    646,
    650,
    652,
    653,
    675,
    676,
    697,
    707,
    712,
    713,
    715,
    728,
    729,
    732,
    738,
    739,
    741,
    745,
    752,
    762,
    772,
    784,
    786,
    790,
    805,
    809,
    810,
    811,
    812,
    820,
    837,
    842,
    846,
    866,
    870,
    874,
    876,
    877,
    878,
    889,
    891,
    894,
    897,
    900,
    902,
    905,
    908,
    910,
    922,
    934,
    935,
    936,
    937,
    941,
    943,
    944,
    948,
    949,
    952,
    959,
    960,
    963,
    969,
    970,
    971,
    976,
    982,
    1051,
    1076,
    1081,
    1083,
    1088,
    1108,
    1109,
    1131,
    1145,
    1149,
    1152,
    1153,
    1158,
    1162,
    1165,
    1176,
    1178,
    1179,
    1182,
    1220,
    1226,
    1250,
    1254,
    1268,
    1277,
    1280,
    1286,
    1304,
    1305,
    1313,
    1314,
    1369,
    1373,
    1408,
    1423,
    1442,
    1446,
    1447,
    1466,
    1468,
    1485,
    1489,
    1491,
    1501,
    1514,
    1521,
    1523,
    1586,
    1590,
    1595,
    1596,
    1601,
    1610,
    1611,
    1613,
    1617,
    1626,
    1630,
    1636,
    1639,
    1641,
    1647,
    1649,
    1653,
    1655,
    1658,
    1659,
}


# load all images in a directory into memory
def load_images(path_original, path_processed):
    src_list, tar_list = list(), list()
    num_images = 1700
    # enumerate filenames in directory, assume all are images
    for i in range(num_images):
        if i in ignore_list:
            continue
        try:
            original_filename = f"Mountain-{str(i)}.jpg"
            processed_filename = f"traced-Mountain-{str(i)}.jpg"
            # load and resize the image
            original_image = load_img(
                path_original + original_filename, target_size=(256, 256)
            )
            # convert to numpy array
            original_image = img_to_array(original_image)
            # load and resize the image
            processed_image = load_img(
                path_processed + processed_filename, target_size=(256, 256)
            )
            # convert to numpy array
            processed_image = img_to_array(processed_image)
            # split into drawified and photo
            src_list.append(processed_image)
            tar_list.append(original_image)
        except:
            print(f"{i},")
    return [asarray(src_list), asarray(tar_list)]


# load datasety
# load dataset
[src_images, tar_images] = load_images(path_original_images, path_processed_images)
print("Loaded: ", src_images.shape, tar_images.shape)
# save as compressed numpy array

savez_compressed(filename, src_images, tar_images)
print("Saved dataset:Â ",filename)